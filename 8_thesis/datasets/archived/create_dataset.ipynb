{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a29bafb0e73c95bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CEFR Dataset Creation",
   "id": "3de0838cf11708fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note: \n",
    "\n",
    "Word to CEFR level maps are fetched from: \n",
    "- kaggle_word_cefr_map: https://www.kaggle.com/datasets/nezahatkk/10-000-english-words-cerf-labelled\n",
    "- oxford_word_cefr_map:  https://www.oxfordlearnersdictionaries.com/wordlists/oxford3000-5000?dataset=english&list=ox5000"
   ],
   "id": "93cb23bf08fbaa44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T14:24:00.420333Z",
     "start_time": "2024-08-16T14:23:56.529149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy \n",
    "import pandas as pd"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T14:24:08.096491Z",
     "start_time": "2024-08-16T14:24:04.047873Z"
    }
   },
   "cell_type": "code",
   "source": "nlp = spacy.load('en_core_web_trf')",
   "id": "d5273f3a0cb85ad6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kawis\\anaconda3\\Lib\\site-packages\\thinc\\shims\\pytorch.py:253: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T22:06:14.332534Z",
     "start_time": "2024-08-14T22:06:14.304232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oxford_map = pd.read_csv('oxford_dataset/oxford_word_cefr_map.csv')\n",
    "kaggle_map = pd.read_csv('kaggle_dataset/kaggle_word_cefr_map_filtered.csv')\n",
    "\n",
    "print(oxford_map['pos'].value_counts())\n",
    "\n",
    "oxford_dict = oxford_map.set_index(['text', 'pos'])['cefr'].to_dict()\n",
    "oxford_dict_word_only = oxford_map.set_index('text')['cefr'].to_dict()\n",
    "kaggle_dict = kaggle_map.set_index('headword')['CEFR'].to_dict()\n"
   ],
   "id": "48f51ca06aa77d3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "noun                  2958\n",
      "verb                  1247\n",
      "adjective             1076\n",
      "adverb                 366\n",
      "pronoun                 77\n",
      "preposition             66\n",
      "determiner              42\n",
      "number                  33\n",
      "conjunction             32\n",
      "exclamation             20\n",
      "modal verb              14\n",
      "ordinal number           5\n",
      "auxiliary verb           3\n",
      "definite article         1\n",
      "indefinite article       1\n",
      "linking verb             1\n",
      "infinitive marker        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_sentence(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    tokens_data = []\n",
    "    for token in doc:\n",
    "        tokens_data.append({\n",
    "            'word': token.text,\n",
    "            'lemma': token.lemma_,\n",
    "            'pos': token.pos_,\n",
    "            'ner': token.ent_type_ if token.ent_type_ else 'O'\n",
    "        })\n",
    "    return tokens_data"
   ],
   "id": "7d708f7c68a21b8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cefr_weights = {\n",
    "    'A1': 1,\n",
    "    'A2': 2,\n",
    "    'B1': 4,\n",
    "    'B2': 7,\n",
    "    'C1': 15,\n",
    "    'C2': 30\n",
    "}\n",
    "def cefr_to_weighted_numeric(cefr_level):\n",
    "    return cefr_weights.get(cefr_level, 1)\n",
    "\n",
    "def numeric_to_cefr(numeric_value):\n",
    "    if numeric_value <= 1.7:\n",
    "        return 'A1'\n",
    "    elif numeric_value <= 2.5:\n",
    "        return 'A2'\n",
    "    elif numeric_value <= 3.5:\n",
    "        return 'B1'\n",
    "    elif numeric_value <= 5.5:\n",
    "        return 'B2'\n",
    "    elif numeric_value <= 8.0:\n",
    "        return 'C1'\n",
    "    else:\n",
    "        return 'C2'\n",
    "\n",
    "def get_cefr_level(word, pos):\n",
    "    word_lower = word.lower()\n",
    "\n",
    "    cefr_level = oxford_dict.get((word_lower, pos.lower()))\n",
    "    if cefr_level:\n",
    "        return cefr_level.upper()\n",
    "\n",
    "    cefr_level = oxford_dict_word_only.get(word_lower)\n",
    "    if cefr_level:\n",
    "        return cefr_level.upper()\n",
    "\n",
    "    # cefr_level = kaggle_dict.get(word_lower)\n",
    "    # if cefr_level:\n",
    "    #     return cefr_level.upper()\n",
    "    \n",
    "    return 'Unknown'"
   ],
   "id": "1551b8b8b2449f24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_sentence_cefr_weighted_percentile(tokens_data):\n",
    "    pos_map = {\n",
    "        'ADJ': 'adjective', \n",
    "        'ADV': 'adverb',\n",
    "        'VERB': 'verb',\n",
    "        'NOUN': 'noun',\n",
    "        'AUX': 'auxiliary verb',\n",
    "        'PRON': 'pronoun',\n",
    "        'SCONJ': 'conjunction',\n",
    "        'CCONJ': 'conjunction',\n",
    "        'DET': 'determiner',\n",
    "        'INTJ': 'interjection',\n",
    "        'NUM': 'number',\n",
    "    }\n",
    "    \n",
    "    weighted_levels = [cefr_to_weighted_numeric(get_cefr_level(token['lemma'], token['pos'])) for token in tokens_data] # if token['pos'] in pos_map]\n",
    "    if not weighted_levels:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    weighted_sum = sum(weighted_levels)\n",
    "    weighted_avg = weighted_sum / len(weighted_levels)\n",
    "\n",
    "    return numeric_to_cefr(weighted_avg)"
   ],
   "id": "23cc88824107f088",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def assign_cefr_to_sentence(sentence):\n",
    "    tokens_data = process_sentence(sentence)\n",
    "    sentence_cefr_level = calculate_sentence_cefr_weighted_percentile(tokens_data)\n",
    "    return sentence_cefr_level"
   ],
   "id": "a75b41f97ddce094",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sentence = f'''If one were to  apply just a hint more kinetic force to the feline's plaything, the creature might shed its lethargic nature and engage in jollity.'''\n",
    "# cefr_level = assign_cefr_to_sentence(sentence)\n",
    "# print(f\"Sentence CEFR Level: {cefr_level}\")"
   ],
   "id": "c59821fd4d4895dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T17:07:09.644104Z",
     "start_time": "2024-08-13T15:20:01.426926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('wikisplit_dataset/wikisplit_dataset_original.csv')\n",
    "print(len(df.index))\n",
    "\n",
    "batch_size = 10000\n",
    "for start in range(0, len(df), batch_size):\n",
    "    end = start + batch_size\n",
    "    print(f'Processing batch {start} to {end}')\n",
    "    batch_df = df.iloc[start:end].copy()\n",
    "\n",
    "    batch_df['level'] = batch_df['text'].apply(assign_cefr_to_sentence)\n",
    "    batch_df.to_csv(f'wikisplit/wikisplit_dataset_original_classified_{start}.csv', index=False)\n",
    "    print(f'Batch {start} to {end} has been saved')\n",
    "\n",
    "print(\"Processing complete.\")"
   ],
   "id": "67832995ed910d6f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kawis\\anaconda3\\Lib\\site-packages\\thinc\\shims\\pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwikisplit_dataset_original.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mlen\u001B[39m(df\u001B[38;5;241m.\u001B[39mindex)\n\u001B[1;32m----> 3\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlevel\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(assign_cefr_to_sentence)\n\u001B[0;32m      5\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50000\u001B[39m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m start \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(df), batch_size):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[0;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4800\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SeriesApply(\n\u001B[0;32m   4918\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4919\u001B[0m         func,\n\u001B[0;32m   4920\u001B[0m         convert_dtype\u001B[38;5;241m=\u001B[39mconvert_dtype,\n\u001B[0;32m   4921\u001B[0m         by_row\u001B[38;5;241m=\u001B[39mby_row,\n\u001B[0;32m   4922\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   4923\u001B[0m         kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m-> 4924\u001B[0m     )\u001B[38;5;241m.\u001B[39mapply()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[1;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_standard()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[0;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[0;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39m_map_values(\n\u001B[0;32m   1508\u001B[0m     mapper\u001B[38;5;241m=\u001B[39mcurried, na_action\u001B[38;5;241m=\u001B[39maction, convert\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_dtype\n\u001B[0;32m   1509\u001B[0m )\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m algorithms\u001B[38;5;241m.\u001B[39mmap_array(arr, mapper, na_action\u001B[38;5;241m=\u001B[39mna_action, convert\u001B[38;5;241m=\u001B[39mconvert)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer(values, mapper, convert\u001B[38;5;241m=\u001B[39mconvert)\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1747\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[7], line 2\u001B[0m, in \u001B[0;36massign_cefr_to_sentence\u001B[1;34m(sentence)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21massign_cefr_to_sentence\u001B[39m(sentence):\n\u001B[1;32m----> 2\u001B[0m     tokens_data \u001B[38;5;241m=\u001B[39m process_sentence(sentence)\n\u001B[0;32m      3\u001B[0m     sentence_cefr_level \u001B[38;5;241m=\u001B[39m calculate_sentence_cefr_weighted_percentile(tokens_data)\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m sentence_cefr_level\n",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m, in \u001B[0;36mprocess_sentence\u001B[1;34m(sentence)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_sentence\u001B[39m(sentence):\n\u001B[1;32m----> 2\u001B[0m     doc \u001B[38;5;241m=\u001B[39m nlp(sentence)\n\u001B[0;32m      3\u001B[0m     tokens_data \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m doc:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\language.py:1049\u001B[0m, in \u001B[0;36mLanguage.__call__\u001B[1;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[0;32m   1047\u001B[0m     error_handler \u001B[38;5;241m=\u001B[39m proc\u001B[38;5;241m.\u001B[39mget_error_handler()\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1049\u001B[0m     doc \u001B[38;5;241m=\u001B[39m proc(doc, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcomponent_cfg\u001B[38;5;241m.\u001B[39mget(name, {}))  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m   1050\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1051\u001B[0m     \u001B[38;5;66;03m# This typically happens if a component is not initialized\u001B[39;00m\n\u001B[0;32m   1052\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE109\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001B[0m, in \u001B[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\spacy_curated_transformers\\pipeline\\transformer.py:242\u001B[0m, in \u001B[0;36mCuratedTransformer.predict\u001B[1;34m(self, docs)\u001B[0m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;66;03m# To ensure that the model's internal state is always consistent with the pipe's.\u001B[39;00m\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_model_all_layer_outputs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_layer_outputs)\n\u001B[1;32m--> 242\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpredict(docs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:334\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutT:\n\u001B[0;32m    331\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001B[39;00m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001B[39;00m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func(\u001B[38;5;28mself\u001B[39m, X, is_train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\spacy_curated_transformers\\models\\architectures.py:651\u001B[0m, in \u001B[0;36mtransformer_model_forward\u001B[1;34m(model, docs, is_train)\u001B[0m\n\u001B[0;32m    648\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransformer_model_forward\u001B[39m(\n\u001B[0;32m    649\u001B[0m     model: TransformerModelT, docs: TransformerInT, is_train: \u001B[38;5;28mbool\u001B[39m\n\u001B[0;32m    650\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[TransformerOutT, TransformerBackpropT]:\n\u001B[1;32m--> 651\u001B[0m     Y, backprop_layer \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m](docs, is_train\u001B[38;5;241m=\u001B[39mis_train)\n\u001B[0;32m    653\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackprop\u001B[39m(dY):\n\u001B[0;32m    654\u001B[0m         backprop_layer(dY)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func(\u001B[38;5;28mself\u001B[39m, X, is_train\u001B[38;5;241m=\u001B[39mis_train)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\spacy_curated_transformers\\models\\with_non_ws_tokens.py:72\u001B[0m, in \u001B[0;36mwith_non_ws_tokens_forward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     70\u001B[0m inner: Model[Tok2PiecesInT, WsTokenAdapterOutT] \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     71\u001B[0m tokens, ws_counts \u001B[38;5;241m=\u001B[39m _filter_tokens(X)\n\u001B[1;32m---> 72\u001B[0m Y_no_ws, backprop_no_ws \u001B[38;5;241m=\u001B[39m inner(tokens, is_train)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# Note: we modify the model outputs in-place. Since we are wrapping the\u001B[39;00m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;66;03m# model, there should be no other consumers. Not sure yet if the same\u001B[39;00m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;66;03m# applies to the gradient (e.g. consider summing two encoders of the\u001B[39;00m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;66;03m# same width downstream.)\u001B[39;00m\n\u001B[0;32m     79\u001B[0m alignments \u001B[38;5;241m=\u001B[39m _create_alignments(model, Y_no_ws, ws_counts)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func(\u001B[38;5;28mself\u001B[39m, X, is_train\u001B[38;5;241m=\u001B[39mis_train)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m layer(X, is_train\u001B[38;5;241m=\u001B[39mis_train)\n\u001B[0;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[0;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func(\u001B[38;5;28mself\u001B[39m, X, is_train\u001B[38;5;241m=\u001B[39mis_train)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\spacy_curated_transformers\\models\\with_strided_spans.py:108\u001B[0m, in \u001B[0;36mwith_strided_spans_forward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m    106\u001B[0m outputs \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m _split_spans(spans, batch_size):\n\u001B[1;32m--> 108\u001B[0m     output, bp \u001B[38;5;241m=\u001B[39m transformer(cast(TorchTransformerInT, batch), is_train\u001B[38;5;241m=\u001B[39mis_train)\n\u001B[0;32m    109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, TransformerModelOutput):\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    111\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m received an unexpected input of type \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(output)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    112\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt can only wrap/be chained with models whose outputs are of type  \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    113\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`TransformerModelOutput` (in almost all cases, models of type `TorchTransformerModelT`)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    114\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[1;34m(self, X, is_train)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[0;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func(\u001B[38;5;28mself\u001B[39m, X, is_train\u001B[38;5;241m=\u001B[39mis_train)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\pytorchwrapper.py:225\u001B[0m, in \u001B[0;36mforward\u001B[1;34m(model, X, is_train)\u001B[0m\n\u001B[0;32m    222\u001B[0m convert_outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mattrs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconvert_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    224\u001B[0m Xtorch, get_dX \u001B[38;5;241m=\u001B[39m convert_inputs(model, X, is_train)\n\u001B[1;32m--> 225\u001B[0m Ytorch, torch_backprop \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mshims[\u001B[38;5;241m0\u001B[39m](Xtorch, is_train)\n\u001B[0;32m    226\u001B[0m Y, get_dYtorch \u001B[38;5;241m=\u001B[39m convert_outputs(model, (X, Ytorch), is_train)\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackprop\u001B[39m(dY: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\shims\\pytorch.py:97\u001B[0m, in \u001B[0;36mPyTorchShim.__call__\u001B[1;34m(self, inputs, is_train)\u001B[0m\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbegin_update(inputs)\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(inputs), \u001B[38;5;28;01mlambda\u001B[39;00m a: \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\shims\\pytorch.py:115\u001B[0m, in \u001B[0;36mPyTorchShim.predict\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mixed_precision):\n\u001B[1;32m--> 115\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model(\u001B[38;5;241m*\u001B[39minputs\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\curated_transformers\\models\\curated_transformer.py:37\u001B[0m, in \u001B[0;36mCuratedTransformer.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     29\u001B[0m     input_ids: Tensor,\n\u001B[0;32m     30\u001B[0m     attention_mask: Optional[AttentionMask] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     31\u001B[0m     token_type_ids: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     32\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PyTorchTransformerOutput:\n\u001B[0;32m     33\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;124;03m    Shapes:\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;124;03m        input_ids, attention_mask, token_type_ids - (batch, seq_len)\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurated_encoder\u001B[38;5;241m.\u001B[39mforward(input_ids, attention_mask, token_type_ids)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\curated_transformers\\models\\roberta\\encoder.py:51\u001B[0m, in \u001B[0;36mRobertaEncoder.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids)\u001B[0m\n\u001B[0;32m     49\u001B[0m layer_outputs \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m---> 51\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m layer(layer_output, attention_mask)\n\u001B[0;32m     52\u001B[0m     layer_outputs\u001B[38;5;241m.\u001B[39mappend(layer_output)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m PyTorchTransformerOutput(\n\u001B[0;32m     55\u001B[0m     embedding_output\u001B[38;5;241m=\u001B[39membeddings, layer_hidden_states\u001B[38;5;241m=\u001B[39mlayer_outputs\n\u001B[0;32m     56\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\curated_transformers\\models\\bert\\layer.py:133\u001B[0m, in \u001B[0;36mBertEncoderLayer.forward\u001B[1;34m(self, x, attn_mask)\u001B[0m\n\u001B[0;32m    130\u001B[0m attn_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattn_output_dropout(attn_out)\n\u001B[0;32m    131\u001B[0m attn_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattn_output_layernorm(x \u001B[38;5;241m+\u001B[39m attn_out)\n\u001B[1;32m--> 133\u001B[0m ffn_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mffn(attn_out)\n\u001B[0;32m    134\u001B[0m ffn_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mffn_output_dropout(ffn_out)\n\u001B[0;32m    135\u001B[0m ffn_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mffn_output_layernorm(attn_out \u001B[38;5;241m+\u001B[39m ffn_out)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\curated_transformers\\models\\bert\\layer.py:102\u001B[0m, in \u001B[0;36mBertFeedForward.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    100\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate(x)\n\u001B[0;32m    101\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(out)\n\u001B[1;32m--> 102\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(out)\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T02:37:15.254224Z",
     "start_time": "2024-08-14T02:37:14.875302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import glob\n",
    "\n",
    "csv_files = glob.glob(f'wikisplit_dataset/wikisplit_dataset_original_classified_*.csv')\n",
    "\n",
    "first_number = int(csv_files[0].split('_')[-1].split('.')[0])\n",
    "last_number = int(csv_files[-1].split('_')[-1].split('.')[0])\n",
    "\n",
    "dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(f'wikisplit_dataset/wikisplit_dataset_original_classified_combined{first_number}_{last_number}.csv', index=False)"
   ],
   "id": "386c5ea7d6a4f4a9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T02:45:36.462002Z",
     "start_time": "2024-08-14T02:45:36.263840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('wikisplit_dataset/wikisplit_dataset_original_classified_combined0_90000.csv')\n",
    "\n",
    "df_a1 = df[df['level'] == 'A1'].sample(2000, random_state=42)\n",
    "df_a2 = df[df['level'] == 'A2'].sample(2000, random_state=42)\n",
    "df_b1 = df[df['level'] == 'B1'].sample(2000, random_state=42)\n",
    "df_b2 = df[df['level'] == 'B2'].sample(2000, random_state=42)\n",
    "df_c1 = df[df['level'] == 'C1'].sample(2000, random_state=42)\n",
    "df_c2 = df[df['level'] == 'C2'].sample(2000, random_state=42)\n",
    "\n",
    "\n",
    "combined_df = pd.concat([df_a1, df_a2, df_b1, df_b2, df_c1, df_c2]).reset_index(drop=True)\n",
    "\n",
    "def split_level(df, level):\n",
    "    df_level = df[df['level'] == level]\n",
    "    train = df_level.sample(1600, random_state=42)\n",
    "    remaining = df_level.drop(train.index)\n",
    "    test = remaining.sample(200, random_state=42)\n",
    "    validation = remaining.drop(test.index)\n",
    "    return train, test, validation\n",
    "\n",
    "train_a1, test_a1, val_a1 = split_level(combined_df, 'A1')\n",
    "train_a2, test_a2, val_a2 = split_level(combined_df, 'A2')\n",
    "train_b1, test_b1, val_b1 = split_level(combined_df, 'B1')\n",
    "train_b2, test_b2, val_b2 = split_level(combined_df, 'B2')\n",
    "train_c1, test_c1, val_c1 = split_level(combined_df, 'C1')\n",
    "train_c2, test_c2, val_c2 = split_level(combined_df, 'C2')\n",
    "\n",
    "train_df = pd.concat([train_a1, train_a2, train_b1, train_b2, train_c1, train_c2]).reset_index(drop=True)\n",
    "test_df = pd.concat([test_a1, test_a2, test_b1, test_b2, test_c1, test_c2]).reset_index(drop=True)\n",
    "val_df = pd.concat([val_a1, val_a2, val_b1, val_b2, val_c1, val_c2]).reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)\n",
    "val_df.to_csv('validation.csv', index=False)"
   ],
   "id": "d9d28a0f4deed694",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c784ac3be2338584"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T00:56:46.873281Z",
     "start_time": "2024-09-02T00:56:46.592082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Original text\n",
    "text = \"Tokenization is the process of breaking down text into smaller units called tokens.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n"
   ],
   "id": "9acdcfa7fd6824d2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T00:57:28.157218Z",
     "start_time": "2024-09-02T00:57:28.153638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(tokens)"
   ],
   "id": "105a3f6420baa29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', '##ization', 'is', 'the', 'process', 'of', 'breaking', 'down', 'text', 'into', 'smaller', 'units', 'called', 'token', '##s', '.']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T00:57:29.239029Z",
     "start_time": "2024-09-02T00:57:29.236483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(token_ids)"
   ],
   "id": "58a1aa39f48998ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19204, 3989, 2003, 1996, 2832, 1997, 4911, 2091, 3793, 2046, 3760, 3197, 2170, 19204, 2015, 1012]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T00:57:30.482567Z",
     "start_time": "2024-09-02T00:57:30.472075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a DataFrame to display\n",
    "import pandas as pd\n",
    "\n",
    "df_tokens = pd.DataFrame({'Token': tokens, 'Token ID': token_ids})\n",
    "print(df_tokens)"
   ],
   "id": "f6b3e0543e24e0d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Token  Token ID\n",
      "0       token     19204\n",
      "1   ##ization      3989\n",
      "2          is      2003\n",
      "3         the      1996\n",
      "4     process      2832\n",
      "5          of      1997\n",
      "6    breaking      4911\n",
      "7        down      2091\n",
      "8        text      3793\n",
      "9        into      2046\n",
      "10    smaller      3760\n",
      "11      units      3197\n",
      "12     called      2170\n",
      "13      token     19204\n",
      "14        ##s      2015\n",
      "15          .      1012\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1a8b3bbd9d6150c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

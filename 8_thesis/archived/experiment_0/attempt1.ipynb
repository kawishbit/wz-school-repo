{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64883d2d-f024-4a14-94c5-35e3cdcc4762",
   "metadata": {},
   "source": [
    "# Llama 3 8B Without QLORA and PEFT | Dataset A"
   ]
  },
  {
   "cell_type": "code",
   "id": "8fb21eb3-677d-460b-ade8-50d0f281a1c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T04:00:51.486334Z",
     "start_time": "2024-08-14T04:00:51.483277Z"
    }
   },
   "source": [
    "import json\n",
    "import wandb\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report,\n",
    "                             confusion_matrix)\n",
    "from transformers import pipeline, BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.4.0+cu124\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T04:00:01.660076Z",
     "start_time": "2024-08-14T04:00:01.578488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_data = json.load(open('../config.json'))\n",
    "HF_TOKEN = config_data['HF_TOKEN']\n",
    "WANDB_TOKEN = config_data['WANDB_TOKEN']\n",
    "\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "run = wandb.init(\n",
    "    project='wz_llama_zeroshot',\n",
    "    config={\"model_name\": \"Meta-Llama-3-8B\"}\n",
    ")"
   ],
   "id": "37209f7d22f871cb",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m config_data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig.json\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m      2\u001B[0m HF_TOKEN \u001B[38;5;241m=\u001B[39m config_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHF_TOKEN\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m WANDB_TOKEN \u001B[38;5;241m=\u001B[39m config_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWANDB_TOKEN\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    305\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    308\u001B[0m     )\n\u001B[1;32m--> 310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'config.json'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "945ad6c0-28d2-4ff7-84d4-ffe079f87b8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T04:00:11.398884Z",
     "start_time": "2024-08-14T04:00:11.395330Z"
    }
   },
   "source": [
    "id_to_label_mapping = {0: 'A1', 1: 'A2', 2: 'B1', 3: 'B2', 4: 'C1', 5: 'C2'}\n",
    "label_to_id_mapping = {'A1': 0, 'A2': 1, 'B1': 2, 'B2': 3, 'C1': 4, 'C2': 5}\n",
    "cefr_levels = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "41fd6b42-826f-4b1c-83f1-a1c5e02cf6d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T04:00:11.913386Z",
     "start_time": "2024-08-14T04:00:11.888880Z"
    }
   },
   "source": [
    "train = pd.read_csv('../datasets/train.csv')\n",
    "test = pd.read_csv('../datasets/test.csv')\n",
    "validation = pd.read_csv('../datasets/validation.csv')"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T04:02:18.294158Z",
     "start_time": "2024-08-14T04:02:18.290605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True\n",
    ")"
   ],
   "id": "26c5725c3ae66285",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T04:02:38.973577Z",
     "start_time": "2024-08-14T04:02:21.113216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    resume_download=None,\n",
    "    device_map=None,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, resume_download=None)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ],
   "id": "dba15151e5a68a6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8edce03082de49a0b5b897c6c19a7aa6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "349cb52a-8de7-4313-bbd0-b21157fc8f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T04:03:26.681872Z",
     "start_time": "2024-08-14T04:03:24.517367Z"
    }
   },
   "source": [
    "# log_thread = threading.Thread(target=log_system_metrics, args=(10,), daemon=True)\n",
    "# log_thread.start()\n",
    "\n",
    "def predict(test_data, prediction_model, prediction_tokenizer):\n",
    "    predictions = []\n",
    "    global cefr_levels\n",
    "    \n",
    "    for index, row in test_data[:5].iterrows():\n",
    "        prompt = f\"\"\"Classify the text below into one of six CEFR levels (A1, A2, B1, B2, C1, C2). Select between these 6 levels: A1, A2, B1, B2, C1, C2.\n",
    "Text: {row['text']}\n",
    "CEFR level: \"\"\"\n",
    "        pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=prediction_model,\n",
    "            tokenizer=prediction_tokenizer,\n",
    "            max_new_tokens=2,\n",
    "            temperature=0.1,\n",
    "        )\n",
    "\n",
    "        result = pipe(prompt)\n",
    "        print(result)\n",
    "        answer = result[0]['generated_text'].split(\"level:\")[-1].strip()\n",
    "        print(answer)\n",
    "        # Determine the predicted category\n",
    "        for level in cefr_levels:\n",
    "            if level.lower() in answer.lower():\n",
    "                predictions.append(level)\n",
    "                break\n",
    "        else:\n",
    "            predictions.append(\"none\")\n",
    "\n",
    "    return predictions\n",
    "y_pred = predict(test, model, tokenizer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Classify the text below into one of six CEFR levels (A1, A2, B1, B2, C1, C2). Select between these 6 levels: A1, A2, B1, B2, C1, C2.\\nText: After four single - season stints at Ohio Wesleyan , Nebraska , Kansas , and Stanford , Yost served as the head football coach for the Michigan Wolverines football team from 1901 through 1923 , and again in 1925 and 1926 .\\nCEFR level: 1\\n'}]\n",
      "1\n",
      "[{'generated_text': 'Classify the text below into one of six CEFR levels (A1, A2, B1, B2, C1, C2). Select between these 6 levels: A1, A2, B1, B2, C1, C2.\\nText:  I am a Christian and do nt want to serve a Muslim army ,  he had written , adding that he had been attending church since 1998 .\\nCEFR level:  B2'}]\n",
      "B2\n",
      "[{'generated_text': 'Classify the text below into one of six CEFR levels (A1, A2, B1, B2, C1, C2). Select between these 6 levels: A1, A2, B1, B2, C1, C2.\\nText: Anari , from Greek ( αναρή ) is a crumbly fresh whey cheese , similar to ricotta , made from goat or sheep milk ; usually unsalted ( though salted versions are available ) , eaten sometimes with a drizzle of honey or carob syrup .\\nCEFR level: 1\\n'}]\n",
      "1\n",
      "[{'generated_text': 'Classify the text below into one of six CEFR levels (A1, A2, B1, B2, C1, C2). Select between these 6 levels: A1, A2, B1, B2, C1, C2.\\nText: After leaving Afghanistan , in 1985 , in Germany , Hangama and Ahmad Wali got married and gave birth to a son named Massieh in 1986 .\\nCEFR level: \\xa0?\\n'}]\n",
      "?\n",
      "[{'generated_text': 'Classify the text below into one of six CEFR levels (A1, A2, B1, B2, C1, C2). Select between these 6 levels: A1, A2, B1, B2, C1, C2.\\nText: Aislinn Connolly is a camogie player who was an All Star winner in 2010 and 2011 and a member of the Team of the Championship for 2011 .\\nCEFR level: 1\\n'}]\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "75e29b3f-a6c5-488c-b50e-9e0a845721f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T11:55:45.659066Z",
     "start_time": "2024-08-12T11:55:45.405047Z"
    }
   },
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "y_true = test['level']\n",
    "\n",
    "def map_func(x):\n",
    "    return label_to_id_mapping.get(x, -1)\n",
    "\n",
    "y_true_mapped = np.vectorize(map_func)(y_true)\n",
    "y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "\n",
    "# Generate accuracy report\n",
    "unique_labels = set(y_true_mapped)  # Get unique labels\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n",
    "    label_y_true = [y_true_mapped[i] for i in label_indices]\n",
    "    label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
    "    label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "    print(f'Accuracy for label {cefr_levels[label]}: {label_accuracy:.3f}')\n",
    "\n",
    "class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=cefr_levels, labels=list(range(len(cefr_levels))))\n",
    "class_report_dict = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=cefr_levels, labels=list(range(len(cefr_levels))), output_dict=True)\n",
    "print('\\nClassification Report:')\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(cefr_levels))))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                              display_labels=cefr_levels)\n",
    "disp.plot()\n",
    "print('\\nConfusion Matrix:')\n",
    "print(conf_matrix)\n",
    "# wandb.log({\n",
    "#     \"Class Proportions\": wandb.sklearn.plot_class_proportions(train['level'], test['test'], cefr_levels),\n",
    "#     \"Confusion Matrix Plot\": wandb.sklearn.plot_confusion_matrix(y_true, y_pred, cefr_levels),\n",
    "#     \"Confusion Matrix\": wandb.plot.confusion_matrix(y_true=y_true, preds=y_pred, class_names=cefr_levels),\n",
    "#     \"Confusion Matrix Disp\": plt,\n",
    "#     \"Confusion Matrix Disp 2\": disp.plot(),\n",
    "#     \"Classification Report\": class_report_dict,\n",
    "#     \"Classification Report DF\": class_report_dict,\n",
    "# })"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['none', 'none', 'none', 'none', 'none']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 5]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 38\u001B[0m\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;28mprint\u001B[39m(conf_matrix)\n\u001B[0;32m     37\u001B[0m y_true \u001B[38;5;241m=\u001B[39m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlevel\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 38\u001B[0m evaluate(y_true, y_pred)\n",
      "Cell \u001B[1;32mIn[17], line 14\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     11\u001B[0m y_pred_mapped \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvectorize(map_func)(y_pred)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Calculate accuracy\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_true\u001B[38;5;241m=\u001B[39my_true_mapped, y_pred\u001B[38;5;241m=\u001B[39my_pred_mapped)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Generate accuracy report\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    229\u001B[0m xp, _, device \u001B[38;5;241m=\u001B[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001B[0;32m    230\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 231\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m _check_targets(y_true, y_pred)\n\u001B[0;32m    232\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[0;32m     77\u001B[0m \n\u001B[0;32m     78\u001B[0m \u001B[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;124;03my_pred : array or indicator matrix\u001B[39;00m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    102\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(y_true, y_pred)\n\u001B[1;32m--> 103\u001B[0m check_consistent_length(y_true, y_pred)\n\u001B[0;32m    104\u001B[0m type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    105\u001B[0m type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    455\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 457\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    458\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    459\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    460\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [1000, 5]"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.show()",
   "id": "88953a6f3edcb223"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T12:47:58.324683Z",
     "start_time": "2024-08-12T12:47:58.315513Z"
    }
   },
   "cell_type": "code",
   "source": "wandb.finish()",
   "id": "22df991a9d9150d0",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7e0b3c4a16b19cb6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

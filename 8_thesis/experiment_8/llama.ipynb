{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Llama",
   "id": "79ecd5a7b47a5ede"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:03:57.482375Z",
     "start_time": "2024-08-31T16:03:48.585864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import wandb\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BitsAndBytesConfig, DataCollatorWithPadding, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix,classification_report\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from datasets import Dataset, DatasetDict\n",
    "import datetime"
   ],
   "id": "9bc8d0baff43d540",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:04:07.798120Z",
     "start_time": "2024-08-31T16:03:57.483414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_data = json.load(open('../config.json'))\n",
    "HF_TOKEN = config_data['HF_TOKEN']\n",
    "WANDB_TOKEN = config_data['WANDB_TOKEN']\n",
    "\n",
    "wandb.login(key=WANDB_TOKEN)\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "config = {\n",
    "    \"per_device_train_batch_size\":8,\n",
    "    \"per_device_eval_batch_size\":8,\n",
    "    \"num_train_epochs\":2,\n",
    "    \"learning_rate\":5e-5,\n",
    "    \"maxlen\": 1000,\n",
    "    \"logging_steps\": 10,\n",
    "    \"num_classes\": 6,\n",
    "    \"num_labels\":6,\n",
    "    \"use_cache\":False,\n",
    "    \"pretraining_tp\":1,\n",
    "    \"model_name\": model_name\n",
    "}\n",
    "\n",
    "run = wandb.init(\n",
    "    project='wz_experimental',\n",
    "    config=config\n",
    ")\n"
   ],
   "id": "5322d58d9b0f3ad9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mkawishbit\u001B[0m (\u001B[33mkawishbit-org\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\kawis\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\repositories\\unirepo\\8_thesis\\experiment_8\\wandb\\run-20240831_230400-23ht9lnc</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kawishbit-org/wz_experimental/runs/23ht9lnc' target=\"_blank\">solar-firefly-71</a></strong> to <a href='https://wandb.ai/kawishbit-org/wz_experimental' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/kawishbit-org/wz_experimental' target=\"_blank\">https://wandb.ai/kawishbit-org/wz_experimental</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/kawishbit-org/wz_experimental/runs/23ht9lnc' target=\"_blank\">https://wandb.ai/kawishbit-org/wz_experimental/runs/23ht9lnc</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:04:07.802321Z",
     "start_time": "2024-08-31T16:04:07.798634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id_to_label_mapping = {0: 'A1', 1: 'A2', 2: 'B1', 3: 'B2', 4: 'C1', 5: 'C2'}\n",
    "label_to_id_mapping = {'A1': 0, 'A2': 1, 'B1': 2, 'B2': 3, 'C1': 4, 'C2': 5}\n",
    "cefr_levels = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]"
   ],
   "id": "7b9eec32951cf283",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:04:07.845497Z",
     "start_time": "2024-08-31T16:04:07.803358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('../datasets/quotes/quotes_train.csv')\n",
    "test = pd.read_csv('../datasets/quotes/quotes_test.csv')\n",
    "validation = train.sample(2091, random_state=42)\n",
    "train = train.drop(validation.index)\n",
    "\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "validation = validation.sample(frac=1).reset_index(drop=True)"
   ],
   "id": "b3207ae36c3b3e7b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:04:07.897499Z",
     "start_time": "2024-08-31T16:04:07.847519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train),\n",
    "    'val': Dataset.from_pandas(validation),\n",
    "    'test': Dataset.from_pandas(test)\n",
    "})\n",
    "dataset"
   ],
   "id": "ecdc212e109f4216",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'level'],\n",
       "        num_rows: 16130\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'label', 'level'],\n",
       "        num_rows: 2091\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'level'],\n",
       "        num_rows: 2692\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:04:07.908750Z",
     "start_time": "2024-08-31T16:04:07.899111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_labels_range(dataset):\n",
    "    unique_labels = set(dataset['train']['label'])\n",
    "    print(f\"Unique labels in the training dataset: {unique_labels}\")\n",
    "    assert all(int(label) in range(6) for label in unique_labels), \"Labels must be in the range 0 to 5\"\n",
    "\n",
    "check_labels_range(dataset)"
   ],
   "id": "2575723bbfa1a187",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the training dataset: {0, 1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:11.144337Z",
     "start_time": "2024-08-31T16:04:07.909774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6, config=config)\n",
    "model.to(device)\n",
    "print(\"Added to device\")"
   ],
   "id": "511557eb15ace221",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kawis\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cfeeb2cc45b4b998fcbb3181afe31eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to device\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:11.423420Z",
     "start_time": "2024-08-31T16:05:11.144852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.0,\n",
    "    target_modules = ['down_proj', 'gate_proj', 'o_proj', 'v_proj', 'up_proj', 'q_proj', 'k_proj'],\n",
    "    bias = 'none',\n",
    "    task_type = 'SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.gradient_checkpointing_enable()"
   ],
   "id": "c02b3d0afc68eaed",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:11.976354Z",
     "start_time": "2024-08-31T16:05:11.423945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ],
   "id": "e7484259de175a89",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:11.979900Z",
     "start_time": "2024-08-31T16:05:11.977372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# collate_fn = DataCollatorWithPadding(\n",
    "#     tokenizer=tokenizer,\n",
    "#     pad_to_multiple_of=8\n",
    "# )"
   ],
   "id": "11275c447cb8e9fa",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:11.984437Z",
     "start_time": "2024-08-31T16:05:11.981233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def preprocess_function(examples):\n",
    "#     return tokenizer(examples['text'], truncation=True, max_length=config['maxlen'])\n",
    "# \n",
    "# tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['text'])\n",
    "# tokenized_datasets.set_format(\"torch\")"
   ],
   "id": "bc60d5e3122f7cb6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:11.989143Z",
     "start_time": "2024-08-31T16:05:11.985457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def compute_metrics(pred):\n",
    "#     print(pred)\n",
    "#     print(f'Label: {str(pred.label_ids)[:60]}')\n",
    "#     print(f'Pred: {str(pred.predictions)[:60]}')\n",
    "#     print(f'Input: {str(pred.inputs)[:60]}')\n",
    "#     labels = pred.label_ids\n",
    "#     predictions = pred.predictions[0].argmax(-1) if isinstance(pred.predictions,\n",
    "#                                                                tuple) else pred.predictions.argmax(-1)\n",
    "# \n",
    "#     m_accuracy = accuracy_score(labels, predictions)\n",
    "# \n",
    "#     precision = precision_score(labels, predictions, average='weighted')\n",
    "#     recall = recall_score(labels, predictions, average='weighted')\n",
    "#     f1 = f1_score(labels, predictions, average='weighted')\n",
    "# \n",
    "#     return {\n",
    "#         'accuracy': m_accuracy,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall,\n",
    "#         'f1': f1\n",
    "#     }"
   ],
   "id": "2683b76858ef7d5d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:11.993747Z",
     "start_time": "2024-08-31T16:05:11.990186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     evaluation_strategy = 'epoch',\n",
    "#     save_strategy = 'epoch',\n",
    "#     logging_steps=config['logging_steps'],\n",
    "#     per_device_train_batch_size=config['per_device_train_batch_size'],\n",
    "#     per_device_eval_batch_size=config['per_device_eval_batch_size'],\n",
    "#     num_train_epochs=config['num_train_epochs'],\n",
    "#     fp16=True,\n",
    "#     report_to=\"wandb\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model='accuracy',\n",
    "#     learning_rate=config['learning_rate'],\n",
    "# )"
   ],
   "id": "38fd6a1a8e04050d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:11.999892Z",
     "start_time": "2024-08-31T16:05:11.995799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# trainer = Trainer(\n",
    "#     model = model,\n",
    "#     args = training_args,\n",
    "#     train_dataset = tokenized_datasets['train'].shuffle(seed=42),\n",
    "#     eval_dataset = tokenized_datasets['val'].shuffle(seed=42),\n",
    "#     tokenizer = tokenizer,\n",
    "#     data_collator = collate_fn,\n",
    "#     compute_metrics = compute_metrics\n",
    "# )"
   ],
   "id": "fb4c8ace9b187300",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:12.004035Z",
     "start_time": "2024-08-31T16:05:12.000898Z"
    }
   },
   "cell_type": "code",
   "source": "# train_result = trainer.train()",
   "id": "2c9bd0cb64a8b478",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:12.008526Z",
     "start_time": "2024-08-31T16:05:12.005071Z"
    }
   },
   "cell_type": "code",
   "source": "# trainer.evaluate()",
   "id": "29b4a17327c06871",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:12.013085Z",
     "start_time": "2024-08-31T16:05:12.009038Z"
    }
   },
   "cell_type": "code",
   "source": "model.config.use_cache = True",
   "id": "3f6eb27cdfe89d83",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T16:05:12.017187Z",
     "start_time": "2024-08-31T16:05:12.014090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# trainer.save_model('model')\n",
    "# tokenizer.save_pretrained('model')"
   ],
   "id": "89a1120a8a49969a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-31T16:05:12.017699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_predictions(p_model, p_test):\n",
    "    print(f'Started prediction at {datetime.datetime.now()}')\n",
    "    sentences = p_test.text.tolist()\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    all_outputs = []\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "\n",
    "        inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=1000)\n",
    "\n",
    "        inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = p_model(**inputs)\n",
    "            all_outputs.append(outputs['logits'])\n",
    "\n",
    "    final_outputs = torch.cat(all_outputs, dim=0)\n",
    "    p_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
    "    p_test['predictions']=p_test['predictions'].apply(lambda l:id_to_label_mapping[l])\n",
    "\n",
    "\n",
    "make_predictions(model,test)"
   ],
   "id": "6c06d58924e6aa30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started prediction at 2024-08-31 23:05:12.021241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kawis\\anaconda3\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:671: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import wandb\n",
    "\n",
    "train['level'] = train['label'].apply(lambda x: id_to_label_mapping[x])\n",
    "test['level'] = test['label'].apply(lambda x: id_to_label_mapping[x])\n",
    "\n",
    "y_pred = test['predictions']\n",
    "\n",
    "y_true = test['level']\n",
    "\n",
    "def map_func(x):\n",
    "    return label_to_id_mapping.get(x, -1)\n",
    "\n",
    "y_true_mapped = np.vectorize(map_func)(y_true)\n",
    "y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "\n",
    "unique_labels = set(y_true_mapped)\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n",
    "    label_y_true = [y_true_mapped[i] for i in label_indices]\n",
    "    label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
    "    label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "    print(f'Accuracy for label {cefr_levels[label]}: {label_accuracy:.3f}')\n",
    "\n",
    "class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=cefr_levels, labels=list(range(len(cefr_levels))))\n",
    "class_report_dict = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=cefr_levels, labels=list(range(len(cefr_levels))), output_dict=True)\n",
    "\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for key, value in class_report_dict.items():\n",
    "    if isinstance(value, dict):\n",
    "        table_data.append([\n",
    "            key,\n",
    "            value.get(\"precision\", 0),\n",
    "            value.get(\"recall\", 0),\n",
    "            value.get(\"f1-score\", 0),\n",
    "            value.get(\"support\", 0)\n",
    "        ])\n",
    "    else:\n",
    "        table_data.append([\n",
    "            key,\n",
    "            0,\n",
    "            0,\n",
    "            value,\n",
    "            class_report_dict[\"weighted avg\"][\"support\"]\n",
    "        ])\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(cefr_levels))))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
    "                              display_labels=cefr_levels)\n",
    "disp.plot()\n",
    "\n",
    "\n",
    "print('\\nConfusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "wandb.log({\n",
    "    \"Class Proportions\": wandb.sklearn.plot_class_proportions(train['level'], test['level'], cefr_levels),\n",
    "    \"Confusion Matrix\": plt,\n",
    "    \"Classification Report\": wandb.Table(data=table_data, columns=['Class/Metric', 'Precision', 'Recall', 'F1-score', 'Support'])\n",
    "})"
   ],
   "id": "3acd2d1fe27c3242",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'Ended prediction at {datetime.datetime.now()}')\n",
    "wandb.finish()"
   ],
   "id": "4aa2ab79c9417b8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "574619a44bb583e6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
